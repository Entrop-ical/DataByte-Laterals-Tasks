{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a8f1dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters: 118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv('Songs.csv')\n",
    "text=\" \".join(df['Lyrics'].astype(str))\n",
    "chars=sorted(list(set(text)))\n",
    "vocab_size=len(chars)\n",
    "char_to_idx={c:i for i,c in enumerate(chars)}\n",
    "idx_to_char={i:c for i,c in enumerate(chars)}\n",
    "print(\"Unique characters:\",vocab_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935cf17",
   "metadata": {},
   "source": [
    "loads the lyrics dataset and combines all lyrics into one text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "762cd585",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=512\n",
    "seq_length=10\n",
    "W_xh=torch.randn(vocab_size,hidden_size)*0.01\n",
    "W_hh=torch.randn(hidden_size,hidden_size)*0.01\n",
    "W_hy=torch.randn(hidden_size,vocab_size)*0.01\n",
    "b_h=torch.zeros(1,hidden_size)\n",
    "b_y=torch.zeros(1,vocab_size)\n",
    "parameters=[W_xh,W_hh,W_hy,b_h,b_y]\n",
    "for p in parameters:p.requires_grad=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f859b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(inputs,targets,h_prev):\n",
    "    loss=0\n",
    "    h=h_prev\n",
    "    for t in range(len(inputs)):\n",
    "        x_t=torch.zeros(1,vocab_size)\n",
    "        x_t[0,inputs[t]]=1\n",
    "        h=torch.tanh(torch.mm(x_t,W_xh)+torch.mm(h,W_hh)+b_h)\n",
    "        y_t=torch.mm(h,W_hy)+b_y\n",
    "        target_tensor=torch.tensor([targets[t]])\n",
    "        loss+=torch.nn.functional.cross_entropy(y_t,target_tensor)\n",
    "    return loss,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_text(h_prev,seed_idx,n):\n",
    "    h=h_prev\n",
    "    x=torch.zeros(1,vocab_size)\n",
    "    x[0,seed_idx]=1\n",
    "    chars=[]\n",
    "    for _ in range(n):\n",
    "        h=torch.tanh(torch.mm(x,W_xh)+torch.mm(h,W_hh)+b_h)\n",
    "        y=torch.mm(h,W_hy)+b_y\n",
    "        probs=torch.softmax(y,1)\n",
    "        idx=torch.multinomial(probs,1).item()\n",
    "        x=torch.zeros(1,vocab_size)\n",
    "        x[0,idx]=1\n",
    "        chars.append(idx_to_char[idx])\n",
    "    return \"\".join(chars)\n",
    "\n",
    "optimizer=torch.optim.Adam(parameters,lr=0.001)\n",
    "p=0\n",
    "for epoch in range(30000):\n",
    "    if p+seq_length+1>=len(text):p=0\n",
    "    inputs=[char_to_idx[ch] for ch in text[p:p+seq_length]]\n",
    "    targets=[char_to_idx[ch] for ch in text[p+1:p+seq_length+1]]\n",
    "    h_prev=torch.zeros(1,hidden_size)\n",
    "    loss,_=forward_pass(inputs,targets,h_prev)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(parameters,5)\n",
    "    optimizer.step()\n",
    "    if epoch%100==0:\n",
    "        print(\"Epoch\",epoch,\"Loss:\",round(loss.item(),4))\n",
    "        print(\"Generated Text:\",sample_text(h_prev,inputs[0],100))\n",
    "    p+=seq_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaefa8a",
   "metadata": {},
   "source": [
    "text sampling from the rnn, set up the optimizer, andthe full training loop with gradient clipping, loss backpropagation, and periodic lyric generation\n",
    "30000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0bcf134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "h_prev = torch.zeros(1, hidden_size)\n",
    "seed_char = text[0]\n",
    "seed_idx = char_to_idx[seed_char]\n",
    "finalt2 = sample_text(h_prev, seed_idx, 2000)\n",
    "with open(\"finalt2.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(finalt2)\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
